## clear the working directory
rm(list=ls())
## load packages
# survival: fitting Cox regressions
# ggplot2: plotting results
# cubature: numeric integration
# tidyverse: data manipulation
library("survival");library("ggplot2"); library("cubature");library("tidyverse");library("gridExtra")
# set the seed
set.seed(102131)

########################
##                    ##
##  Helper functions  ##
##                    ##
########################

## function for simulating survival times with Weibull baseline hazard
# eta: vector containing the log hazard (linear predictor) for each subject
# lambda: scale parameter for the baseline hazard
# p: shape paramter for the baseline hazard
# gen_Ct: function for generating censoring times, default is exponential with mean 5 truncated at t=1
gen_St <- function(eta, lambda, p, gen_Ct = function(N) pmin(1,rexp(N, 1/5)) ){
    N <- length(eta)
    U <- runif(N, 0, 1)
    St = (-log(U)/(lambda*exp(eta)))^(1/p)
    Ct = gen_Ct(N)
    
    data.frame("event" = as.numeric(St<=Ct), "time" = pmin(St,Ct), "eta" = eta)
}

### Integration functions
### Note that we need two different functions since there is a double integral in the specificity formula
## function for integrating incident sensitivity
my_fn_sens <- function(x, t, lambda=1, p=1, mn_eta=0, sigma_eta=2){
    lambda*p*t^(p-1)*exp(x[1])*exp(-lambda*t^p*exp(x[1]))*dnorm(x[1], mean=mn_eta, sd=sigma_eta)
}

my_fn_spec <- function(x, lambda=1, p=1, mn_eta=0, sigma_eta=2){
    lambda*p*x[2]^(p-1)*exp(x[1])*exp(-lambda*x[2]^p*exp(x[1]))*dnorm(x[1], mean=mn_eta, sd=sigma_eta)
}
## function for integrating dynamic specificity
# my_fn_spec <- function(x, lambda=1, p=1, mn_eta=0, sigma_eta=2){
#     lambda*p*x[2]^(p-1)*exp(x[1])*exp(-lambda*x[2]^p*exp(x[1]))*dnorm(x[1], mean=mn_eta, sd=sigma_eta)
# }
# my_fn_spec_v <- function(x, lambda=1, p=1, mn_eta=0, sigma_eta=2){
#     ret <- apply(x, 2, function(z) lambda*p*z[2]^(p-1)*exp(z[1])*exp(-lambda*z[2]^p*exp(z[1]))*dnorm(z[1], mean=mn_eta, sd=sigma_eta))
#     matrix(ret, nrow=nrow(x), ncol=ncol(x))
# }





####################################################################################
##                                                                                ##
##  Simulating Data for Large Sample Validation of Theoretical I/D AUC estimates  ##
##                                                                                ##
####################################################################################


## We simulate data generated by a "true" underlying  Cox model of the form: log \lambda_i(t|.) = log \lambda_0(t) + \eta_i
##    Model: the true model using 3 predictors: \eta_i1 = X_i1*\beta_1 +  X_i2*\beta_2 +  X_i3*\beta_3
## True beta vector
Beta <- c(1,-1,0.25)
## we assume X_ip independent standard normal (i.e.  X_ip ~ N(0, 1) for p = 1,2,3)
## so then \eta_i ~ N(0, \sigma_\eta^2 = (1^2 + 1^2 + 0.25^2))
## That is, the linear predictor is normally distributed with mean zero and variance 3

## set the time point to consider
t_i <- 0.145
eta_ij <- 1.76767677
## vector of max times to loop over
t_max_vec <- 10^(0:10)
## set the range of integration for eta
eta_min <- -Inf
eta_max <- Inf
integral_result <- data.frame(t_max = t_max_vec, "specificity" = NA)
for(t_test in seq_along(t_max_vec)){
    # get current maximum for numeric integration of the "time" domain
    t_max <- t_max_vec[t_test]
    integral_result[t_test,2] <- 
        adaptIntegrate(my_fn_spec, lowerLimit=c(-Inf, t_i), upperLimit=c(eta_ij, t_max), lambda=2, p=2, sigma_eta =  sqrt(sum(Beta^2)))$integral/
        adaptIntegrate(my_fn_spec, lowerLimit=c(-Inf, t_i), upperLimit=c(Inf, t_max), lambda=2, p=2, sigma_eta =  sqrt(sum(Beta^2)))$integral
}

plt_spec <- 
    integral_result %>% 
    ggplot(aes(x=t_max,y=specificity)) + 
    geom_point() + 
    geom_line() + theme_classic() + scale_x_log10()



## simulate some data
## Simulate the data
## Number of subjects used to fit the model -- use a very large number so we can validate our theoretical results
N_obs  <- 10000000
## simulate data that are used to obtain true log hazard for each subject
X  <- matrix(rnorm(N_obs*3), ncol=3, nrow=N_obs)
## obtain true linear predictor (less log hazard) for each subject
eta <- X %*% Beta
## simulate survival times/event indicators for each subject in the data
## here we set censoring time to infinity -- this gives us a sense of the true distribution of survival times
data <- gen_St(eta=eta,lambda=2, p=2, gen_Ct = function(N) rep(Inf,N))

plt_surv_time <- 
    data %>% 
    ggplot(aes(x=time)) + 
    geom_histogram() + 
    theme_classic()

grid.arrange(plt_spec,plt_surv_time,ncol=2)
round(quantile(data$time, seq(0,0.9999,len=50)),2)
