---
title: "Simulation example for one iteration"
author: "Ying Jin"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 4
)

# packages
library("survival")
library("ggplot2")
theme_minimal()
library(ggpubr)
library("cubature")
library("tidyverse")
library(here)
library(risksetROC)
library(mgcv)
library(scam)
library("clinfun")
library(kableExtra)

# helper functions
source(here("Code/Simulation/helpers.R"))
```



In this vignette, we will go over the simulation study corresponding to Section 4, using one simulated dataset as an example. 

# Data generation

Each simulated subject includes the following components: 

- Covariates $\mathbf{X}$: The three covariates associated with survival outcome are generated independently from standard normal distribution. 

- True Survival time $T^*$: In this simulation study, the true survival time is generated from a Cox Proportional Hazard Model with Weiball baseline distribution. The log hazard is linearly correlated with covariates as below:

$$log \lambda(t|\boldsymbol{X}) = log \lambda_0(t) + \boldsymbol{X}^t \boldsymbol{\beta}, t>0$$

with $\boldsymbol{\beta} = (1, -1, 0.25)$ and Weibull baseline hazard $\lambda_0(t) = p\theta t^{p-1}$, $[\theta, p]^t = [2, 2]^t$. 

- True censoring time $C$: Censoring times are simulated for Unifrom(0.5, 1), independently of event times or covariates. There is also an overall endpoint of follow-up $\tau=1$. No observation is made after this time point.

- Observed survival outcome: The earlier between true survival time and true censoring time ($T = min(T^*, C)$) and event indicator $\delta=I(T^*\leq C)$.

- Noise $\mathbf{Z}$. These variables are generated from standard normal distribution. They are not correlated with either the covariates or the outcome, thus should make no contribution to prediction. 

Below is overview of one simulated dataset: 

```{r}
N <- 500 # sample size
Beta <- c(1,-1,0.25) # true coefficient
p <- 3 # number of covariates 


X <- matrix(rnorm(N*3), ncol=p, nrow=N) # covariates
Z <- matrix(rnorm(N*100), ncol = 100, nrow = N) # noise
data <- gen_St(eta=X %*% Beta, lambda=2, p=2, 
                gen_Ct = function(N){
                  sample(c(0.5, 1), size = N, replace = T)}) # outcome
data <- rename(data, true_eta = eta)
data$X <- I(X)
data$Z <- I(Z)
```

Once the data is generated, we need to split the sample into training and testing set. We use 50% of the subjects as the traininig set and the rest as the testing set. 

```{r}
N_obs <- N*0.5
data_train <- data[1:N_obs,]
data_test  <- data[-c(1:N_obs),]
```

Below is an example of survival curves on one simualted dataset

```{r, fig.width=6}
par(mfrow = c(1, 2))
# Kaplan-Meier curve
plot(survfit(Surv(time, event)~1, data = data_train), xlab = "Time", ylab = "Survival", 
     main = "Trainind set")
plot(survfit(Surv(time, event)~1, data = data_test), xlab = "Time", ylab = "Survival",
     main = "Testing set")
```


# Model overfit

To investigate the effect of model overfit on the behavior of estimators, we fit three different Cox Proportional Hazard models

1. Not overfitted: $log \lambda(t|\boldsymbol{X}) = log \lambda_0(t) + \boldsymbol{X}^t \boldsymbol{\beta}$
2. Moderately overfitted: $log \lambda(t|\boldsymbol{X}) = log \lambda_0(t) + \boldsymbol{X}^t \boldsymbol{\beta}+\sum_{j=1}^{20}Z_j\gamma_j$
3. Severely overfitted: $log \lambda(t|\boldsymbol{X}) = log \lambda_0(t) + \boldsymbol{X}^t \boldsymbol{\beta}+\sum_{j=1}^{100}Z_j\gamma_j$

The severely overfitted model has 120 covariates, which is about half of the training sample size. Therefore, it is possible for the dataset to have less unique evens than the number of covariates. In such cases, the cox model would fail to fit. In the manuscript, such datasets with numeric issues are removed and replace with new datasets. 

## Cox models

```{r}
# Fit cox models on training data
# true model
fit_1 <- tryCatch(expr = coxph(Surv(time, event) ~ X, data=data_train), warning = function(x){NULL})
# moderately overfitted
fit_2 <- tryCatch(expr = coxph(Surv(time, event) ~ X + Z[,1:20], data=data_train), 
                    warning = function(x){NULL})
# severely overfitted  
fit_3 <- tryCatch(expr = coxph(Surv(time, event) ~ X + Z, data=data_train),
                    warning = function(x){NULL})
```


## Incident/Dynamic AUC estimators

In this simulation study, we well compare the following three estimators:

- Heagerty & Zheng estimator (HZ). This is a semi-parametric estimator, since it incorporates the term $exp(\boldsymbol{X}^T\boldsymbol{\beta})$ as weights for estimation of sensitivity. 

- Non-parametric estimator (NP). This estimators is established on plug-in principals, using the proportion of true positive and true negative observations for estimation of sensitivity and specificity, respectively. 
- Smoothed non-parametric estimator (SNP). This is a smoothed version of the non-parametric estimator above.

At a specificity time point, all three methods estimate sensitivity and specificity at a series of discrete values of $\boldsymbol{X}^T\boldsymbol{\beta}$ to get an ROC curve, and use its integral as estimate of Incident/Dynamic AUC.

```{r}
# in-sample estimates
# unique time and biomarker values of training sample
t_uni_train <- unique(data_train$time[data_train$event==1])
nt_uni_train <- length(t_uni_train)

# AUC estimates
auc_est1 <- tv_auc(fit_1$linear.predictors, data_train, t_uni_train, nt_uni_train)
auc_est2 <-  tv_auc(fit_2$linear.predictors, data_train, t_uni_train, nt_uni_train)
auc_est3 <-  tv_auc(fit_3$linear.predictors, data_train, t_uni_train, nt_uni_train)

# plot  
bind_rows(data.frame(auc_est1), data.frame(auc_est2), data.frame(auc_est3), .id = "Model") %>% 
  mutate(Model = factor(Model, levels = 1:3, labels = c("No noise", "20 noise", "100 noise")),
) %>%
  pivot_longer(3:5) %>%
  ggplot(aes(x=time, y=value))+
  geom_point(size = 0.5)+
  facet_grid(rows = vars(Model), col = vars(name))+
  labs(x="Time", y="AUC")
```


```{r}
# out-of-sample estimates
# estimated risk scores
## based on model trained in-sample
test_eta1 <- as.vector(data_test$X %*% coef(fit_1))
test_eta2 <- as.vector(cbind(data_test$X,data_test$Z[,1:20]) %*% coef(fit_2))
test_eta3 <- as.vector(cbind(data_test$X,data_test$Z) %*% coef(fit_3))

# unique event time in the test set
t_uni_test <- unique(data_test$time[data_test$event==1])
nt_uni_test <- length(t_uni_test)

#  AUC estimates
test_auc_est1 <- tv_auc(test_eta1, data_test, t_uni_test, nt_uni_test)
test_auc_est2 <- tv_auc(test_eta2, data_test, t_uni_test, nt_uni_test)
test_auc_est3 <- tv_auc(test_eta3, data_test, t_uni_test, nt_uni_test)

# plot  
bind_rows(data.frame(test_auc_est1), data.frame(test_auc_est2), data.frame(test_auc_est3),
          .id = "Model") %>% 
  mutate(Model = factor(Model, levels = 1:3, labels = c("No noise", "20 noise", "100 noise"))) %>%
  pivot_longer(3:5) %>%
  ggplot(aes(x=time, y=value))+
  geom_point(size = 0.5)+
  facet_grid(rows = vars(Model), col = vars(name))+
  labs(x="Time", y="AUC")
```



## Concordance estimators:

Here we compare the behavior of the following estimators: 

- Semi-parmaetric: Heagerty-Zheng, Gonen-Heller
- Non-parametric: weighted integral of non-parametric AUC, weighted integral of smoothed non-parametric AUC, Harrell's C-index. 

Please note that for weighted integral, the weight of Incident/Dynamic AUC at a specific time points is derived from marginal survival and density function of survival time. The semi-parametric concordance proposed by Heagerty & Zheng used Kaplan-Meier estimator directly. However, this paper proposed the use of smoothed Kaplan-Meier curve. 

```{r}
# in-sample
KM_fit_train <- survfit(Surv(time,event)~1, timefix=FALSE, data=data_train)
KM_est_train <- KM_fit_train$surv[KM_fit_train$n.event>0]
# out-of-sample
KM_fit_test <- survfit(Surv(time,event)~1, timefix=FALSE, data=data_test)
KM_est_test <- KM_fit_test$surv[KM_fit_test$n.event>0]
```


```{r}
# in-sample
concord1 <- concord(data_train, KM_est_train, auc_est1, fit_1$coefficients, 
                    data_train$X)
concord2 <- concord(data_train, KM_est_train, auc_est2, fit_2$coefficients, 
                    cbind(data_train$X, data_train$Z[, 1:20]))
concord3 <- concord(data_train, KM_est_train, auc_est3, fit_3$coefficients, 
                    cbind(data_train$X, data_train$Z))
# out-of-sample
test_concord1 <- concord(data_test, KM_est_test, test_auc_est1, fit_1$coefficients, data_test$X)
test_concord2 <- concord(data_test, KM_est_test, test_auc_est2, fit_2$coefficients, 
                         cbind(data_test$X, data_test$Z[, 1:20]))
test_concord3 <- concord(data_test, KM_est_test, test_auc_est3, fit_3$coefficients, 
                         cbind(data_test$X, data_test$Z))
```

Now let's take a brief look at the results: 

```{r, echo=FALSE}
concord_est_train <- rbind(concord1, concord2, concord3) %>%
  data.frame(check.names = F) %>%
     mutate(Model = c("No noise", "20 noise", "100 noise"), .before=1) 

concord_est_test <- rbind(test_concord1, test_concord2, test_concord3) %>%
      data.frame(check.names = F) 

bind_cols(concord_est_train, concord_est_test, .name_repair = "minimal") %>%
  kable( table.attr="style=\"color:black;\"", digits = 3) %>%
  kable_styling(full_width = F) %>%
  add_header_above(c(" " = 1, "In-sample" = 5, "Out-of-sample" = 5))
```
